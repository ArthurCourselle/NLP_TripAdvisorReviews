model_path: "examples/Rnn_Classification/"

tokenizer:
  type: "bpe"
  # checkpoint: "examples/Rnn_Classification/tokenizer.json"
  params:
    vocab_size: 10000
    min_frequency: 2

augmented_data: "augmented.csv"

vectorizer:
  type: "word2vec"
  is_embedding: true
  params:
    max_features: 1000  # This is fine
  #   stop_words: "english"
  #   norm: "l2"
  #   use_idf: true
  #   smooth_idf: true
# vectorizer:
#   type: "word2vec"
#   checkpoint: null  
#   params:
#     vector_size: 1000
#     window: 5
#     min_count: 1
#     workers: 4
#     epochs: 5
#     topn: 10 


model:
  type: "rnn-classification"
  # checkpoint: "examples/Rnn_Classification/best_model.pt"
  params:
    vocab_size: 10000
    embedding_dim: 100
    hidden_size: 256
    num_layers: 1
    output_dim: 5
    dropout_rate: 0.2
    lr: 0.0001
    batch_size: 32
    epochs: 500
    # patience: 5
    scheduler: true 
    device: "cuda"