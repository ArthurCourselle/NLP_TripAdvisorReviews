model_path: "examples/Rnn_Classification/"

tokenizer:
  type: "bpe"
  # checkpoint: "examples/Rnn_Classification/tokenizer.json"
  params:
    vocab_size: 10000
    min_frequency: 2

augmented_data: "augmented.csv"

# vectorizer:
#   type: "tf-idf"
#   params:
#     max_features: 1000  # This is fine
#     stop_words: "english"
#     norm: "l2"
#     use_idf: true
#     smooth_idf: true
# vectorizer:
#   type: "word2vec"
#   checkpoint: null  
#   params:
#     vector_size: 1000
#     window: 5
#     min_count: 1
#     workers: 4
#     epochs: 5
#     topn: 10 


model:
  type: "rnn-classification"
  # checkpoint: "examples/Rnn_Classification/best_model.pt"
  params:
    input_dim: 128
    hidden_dims: 64
    output_dim: 5
    dropout_rate: 0.2
    lr: 0.0001
    batch_size: 128
    epochs: 40
    # patience: 5
    scheduler: true 
    device: "cuda"